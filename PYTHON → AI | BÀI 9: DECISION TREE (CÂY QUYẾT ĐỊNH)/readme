1ï¸âƒ£ Decision Tree lÃ  gÃ¬?

ğŸ‘‰ AI Ä‘áº·t cÃ¢u há»i dáº¡ng:

Äiá»ƒm â‰¥ 5?

ToÃ¡n â‰¥ 6?

Anh â‰¥ 7?

â¡ï¸ Cuá»‘i cÃ¹ng ra quyáº¿t Ä‘á»‹nh Äáº­u / Rá»›t

2ï¸âƒ£ Chuáº©n bá»‹ dá»¯ liá»‡u (2 Ä‘áº·c trÆ°ng)
import pandas as pd

data = {
    "math":    [4, 5, 6, 7, 8, 9],
    "english": [4, 5, 6, 7, 8, 9],
    "passed":  [0, 0, 1, 1, 1, 1]
}

df = pd.DataFrame(data)

X = df[["math", "english"]]
y = df["passed"]

3ï¸âƒ£ Chia train / test
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

4ï¸âƒ£ Train Decision Tree
from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier(max_depth=3)
model.fit(X_train, y_train)

5ï¸âƒ£ Dá»± Ä‘oÃ¡n
print(model.predict([[7, 6]]))  # 1 = Ä‘áº­u
print(model.predict([[4, 5]]))  # 0 = rá»›t

6ï¸âƒ£ ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
from sklearn.metrics import accuracy_score

y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))

7ï¸âƒ£ So sÃ¡nh vá»›i Logistic Regression

ğŸ‘‰ Decision Tree:

Dá»… hiá»ƒu

Overfit náº¿u sÃ¢u quÃ¡

ğŸ‘‰ Logistic Regression:

á»”n Ä‘á»‹nh

KhÃ³ giáº£i thÃ­ch hÆ¡n
