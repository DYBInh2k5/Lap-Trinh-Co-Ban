1ï¸âƒ£ Random Forest lÃ  gÃ¬?

ğŸ‘‰ Táº¡o nhiá»u cÃ¢y quyáº¿t Ä‘á»‹nh
ğŸ‘‰ Má»—i cÃ¢y há»c dá»¯ liá»‡u khÃ¡c nhau
ğŸ‘‰ Káº¿t quáº£ = Ä‘a sá»‘ phiáº¿u

â¡ï¸ Ãt overfitting, ráº¥t phá»• biáº¿n

2ï¸âƒ£ Train Random Forest
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

X = df[["math", "english"]]
y = df["passed"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

model = RandomForestClassifier(
    n_estimators=100,
    random_state=42
)

model.fit(X_train, y_train)

3ï¸âƒ£ Dá»± Ä‘oÃ¡n & Ä‘Ã¡nh giÃ¡
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))


ğŸ‘‰ ThÆ°á»ng cao hÆ¡n Decision Tree

4ï¸âƒ£ Dá»± Ä‘oÃ¡n thá»±c táº¿
print(model.predict([[6, 8]]))  # 1 = Ä‘áº­u
print(model.predict([[4, 5]]))  # 0 = rá»›t

5ï¸âƒ£ Feature Importance (ráº¥t quan trá»ng)
import pandas as pd

importance = model.feature_importances_
print(pd.DataFrame({
    "feature": X.columns,
    "importance": importance
}))


ğŸ‘‰ Biáº¿t mÃ´n nÃ o áº£nh hÆ°á»Ÿng nhiá»u hÆ¡n
